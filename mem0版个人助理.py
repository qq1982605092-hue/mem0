# final_working_health.py
# æœ€ç»ˆå·¥ä½œç‰ˆ - åŸºäºè°ƒè¯•ç»“æœçš„æ­£ç¡®å®ç°

import os
import time
from mem0 import Memory
from openai import OpenAI
import streamlit as st

# APIé…ç½®
API_KEY = "sk-21LnRSoxMhJcF51LwUHcQzUsc9KSbTMUgwBD9db1wfyobpQu"
BASE_URL = "https://api.aiclaude.site/v1"

os.environ["OPENAI_API_KEY"] = API_KEY
os.environ["OPENAI_BASE_URL"] = BASE_URL

COLLECTION = f"health_1755158035"

# Mem0é…ç½®
config = {
    "llm": {
        "provider": "openai",
        "config": {
            "model": "gpt-4o-mini",
            "api_key": API_KEY,
        }
    },
    "embedder": {
        "provider": "openai",
        "config": {
            "model": "text-embedding-3-small",
            "api_key": API_KEY,
        }
    },
    "vector_store": {
        "provider": "qdrant",
        "config": {
            "host": "localhost",
            "port": 6333,
            "collection_name": COLLECTION,
        }
    }
}

# å¥åº·åŠ©ç†ç±»
class HealthBot:
    def __init__(self, user_id):
        self.user_id = user_id
        self.memory = Memory.from_config(config)
        self.client = OpenAI(api_key=API_KEY, base_url=BASE_URL)
        self.conversation_history = []  # æœ¬åœ°å¯¹è¯å†å²
    
    def extract_memories(self, search_result):
        """ä»æœç´¢ç»“æœä¸­æå–è®°å¿†æ–‡æœ¬"""
        memories_text = []
        
        # å¤„ç†å„ç§å¯èƒ½çš„è¿”å›æ ¼å¼
        if isinstance(search_result, dict):
            # å¦‚æœæ˜¯å­—å…¸ï¼ŒæŸ¥æ‰¾åŒ…å«åˆ—è¡¨çš„é”®
            for key, value in search_result.items():
                if isinstance(value, list):
                    # æ‰¾åˆ°åˆ—è¡¨ï¼Œæå–å†…å®¹
                    for item in value[:3]:  # æœ€å¤š3æ¡
                        if isinstance(item, dict):
                            text = item.get('memory') or item.get('text') or item.get('content') or str(item)
                        else:
                            text = str(item)
                        memories_text.append(text)
                    break
                elif isinstance(value, str):
                    memories_text.append(value)
                    break
        elif isinstance(search_result, list):
            # å¦‚æœç›´æ¥æ˜¯åˆ—è¡¨
            for item in search_result[:3]:
                if isinstance(item, dict):
                    text = item.get('memory') or item.get('text') or str(item)
                else:
                    text = str(item)
                memories_text.append(text)
        
        return memories_text
    
    def chat(self, message):
        # æ·»åŠ åˆ°æœ¬åœ°å†å²
        self.conversation_history.append(f"ç”¨æˆ·: {message}")
        
        # å­˜å‚¨åˆ°Mem0
        try:
            self.memory.add(f"ç”¨æˆ·: {message}", user_id=self.user_id)
        except:
            pass
        
        # æ„å»ºä¸Šä¸‹æ–‡ - ä½¿ç”¨æœ¬åœ°å†å² + è®°å¿†æœç´¢
        context = ""
        
        # 1. æœ€è¿‘çš„å¯¹è¯å†å²
        if self.conversation_history:
            recent = self.conversation_history[-6:]  # æœ€è¿‘3è½®å¯¹è¯
            context = "æœ€è¿‘å¯¹è¯:\n" + "\n".join(recent) + "\n\n"
        
        # 2. å°è¯•æœç´¢ç›¸å…³è®°å¿†
        try:
            search_result = self.memory.search(message, user_id=self.user_id, limit=3)
            memories = self.extract_memories(search_result)
            
            if memories:
                context += "ç›¸å…³è®°å½•:\n"
                for mem in memories:
                    context += f"- {mem}\n"
        except:
            # å¦‚æœæœç´¢å¤±è´¥ï¼Œä»…ä½¿ç”¨å¯¹è¯å†å²
            pass
        
        # è°ƒç”¨GPT
        response = self.client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": "ä½ æ˜¯ä¸“ä¸šçš„å¥åº·åŠ©ç†ã€‚åŸºäºå¯¹è¯å†å²å’Œç”¨æˆ·é—®é¢˜ï¼Œæä¾›ä¸“ä¸šã€æ¸©æš–çš„å¥åº·å»ºè®®ã€‚å›ç­”ç®€æ´ï¼Œ100å­—ä»¥å†…ã€‚"},
                {"role": "user", "content": f"{context}\nå½“å‰é—®é¢˜: {message}"}
            ],
            max_tokens=150,
            temperature=0.7
        )
        
        reply = response.choices[0].message.content.strip()
        
        # æ·»åŠ åˆ°å†å²
        self.conversation_history.append(f"åŠ©ç†: {reply}")
        
        # å­˜å‚¨åˆ°Mem0
        try:
            self.memory.add(f"åŠ©ç†: {reply}", user_id=self.user_id)
        except:
            pass
        
        return reply

# ==================== Streamlitç•Œé¢ ====================

st.set_page_config(page_title="å¥åº·åŠ©ç†", page_icon="ğŸ¥", layout="wide")

# æ ‡é¢˜æ 
col1, col2, col3 = st.columns([2, 1, 1])
with col1:
    st.title("ğŸ¥ AIå¥åº·åŠ©ç†")
with col2:
    st.caption(f"GPT-4o-mini")
with col3:
    st.caption(f"é›†åˆ: {COLLECTION[:15]}...")

# ä¾§è¾¹æ 
with st.sidebar:
    user_id = st.text_input("ç”¨æˆ·ID", "user1")
    
    st.divider()
    
    # å¿«é€Ÿæé—®
    st.subheader("ğŸ’¡ å¿«é€Ÿæé—®")
    questions = [
        "æˆ‘æœ€è¿‘å¤´ç—›é¢‘ç¹",
        "è¡€å‹é«˜è¦æ³¨æ„ä»€ä¹ˆ",
        "å¦‚ä½•æ”¹å–„ç¡çœ ",
        "æ„Ÿå†’äº†æ€ä¹ˆåŠ",
        "ç¼“è§£å‹åŠ›çš„æ–¹æ³•"
    ]
    
    for q in questions:
        if st.button(q, key=q, use_container_width=True):
            st.session_state.pending_question = q
    
    st.divider()
    
    # æ“ä½œæŒ‰é’®
    col1, col2 = st.columns(2)
    with col1:
        if st.button("ğŸ”„ æ–°å¯¹è¯", use_container_width=True):
            if "bot" in st.session_state:
                st.session_state.bot.conversation_history = []
            st.session_state.messages = []
            st.rerun()
    
    with col2:
        if st.button("ğŸ“Š å†å²", use_container_width=True):
            if "bot" in st.session_state and st.session_state.bot.conversation_history:
                st.info(f"å…±{len(st.session_state.bot.conversation_history)}æ¡è®°å½•")

# åˆå§‹åŒ–
if "messages" not in st.session_state:
    st.session_state.messages = []

if "bot" not in st.session_state:
    with st.spinner("åˆå§‹åŒ–ä¸­..."):
        try:
            st.session_state.bot = HealthBot(user_id)
            st.success("âœ… ç³»ç»Ÿå°±ç»ª", icon="âœ…")
        except Exception as e:
            st.error(f"åˆå§‹åŒ–å¤±è´¥: {e}")
            st.stop()

# æ¬¢è¿æ¶ˆæ¯
if not st.session_state.messages:
    welcome = """ğŸ‘‹ ä½ å¥½ï¼æˆ‘æ˜¯ä½ çš„AIå¥åº·åŠ©ç†ã€‚

æˆ‘å¯ä»¥å¸®ä½ è§£ç­”å¥åº·é—®é¢˜ã€åˆ†æç—‡çŠ¶ã€æä¾›ç”Ÿæ´»å»ºè®®ã€‚

è¯·æè¿°ä½ çš„å¥åº·çŠ¶å†µæˆ–ç›´æ¥ç‚¹å‡»å·¦ä¾§çš„å¿«é€Ÿæé—®ã€‚"""
    st.session_state.messages.append({"role": "assistant", "content": welcome})

# æ˜¾ç¤ºå¯¹è¯
for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.write(msg["content"])

# å¤„ç†å¿«é€Ÿæé—®
if "pending_question" in st.session_state:
    question = st.session_state.pending_question
    del st.session_state.pending_question
    
    # æ˜¾ç¤ºé—®é¢˜
    with st.chat_message("user"):
        st.write(question)
    st.session_state.messages.append({"role": "user", "content": question})
    
    # ç”Ÿæˆå›ç­”
    with st.chat_message("assistant"):
        with st.spinner("åˆ†æä¸­..."):
            answer = st.session_state.bot.chat(question)
            st.write(answer)
    st.session_state.messages.append({"role": "assistant", "content": answer})

# èŠå¤©è¾“å…¥
if prompt := st.chat_input("è¯·æè¿°ä½ çš„å¥åº·é—®é¢˜..."):
    # æ˜¾ç¤ºç”¨æˆ·æ¶ˆæ¯
    with st.chat_message("user"):
        st.write(prompt)
    st.session_state.messages.append({"role": "user", "content": prompt})
    
    # ç”Ÿæˆå›å¤
    with st.chat_message("assistant"):
        with st.spinner("æ€è€ƒä¸­..."):
            response = st.session_state.bot.chat(prompt)
            st.write(response)
    st.session_state.messages.append({"role": "assistant", "content": response})

# åº•éƒ¨æç¤º
st.markdown("---")
st.caption("âš ï¸ å¥åº·å»ºè®®ä»…ä¾›å‚è€ƒï¼Œä¸¥é‡ç—‡çŠ¶è¯·åŠæ—¶å°±åŒ»")

# è¿è¡Œ: streamlit run final_working_health.py