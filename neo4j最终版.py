# enhanced_health_mem0_neo4j.py
# å®Œå–„çš„Mem0å¥åº·åŠ©ç† - ä½¿ç”¨Neo4jå›¾æ•°æ®åº“å’ŒQdrantå‘é‡æ•°æ®åº“

import os
import time
from mem0 import Memory
from openai import OpenAI
import streamlit as st
import json

# APIé…ç½®
API_KEY = "sk-21LnRSoxMhJcF51LwUHcQzUsc9KSbTMUgwBD9db1wfyobpQu"
BASE_URL = "https://api.aiclaude.site/v1"

os.environ["OPENAI_API_KEY"] = API_KEY
os.environ["OPENAI_BASE_URL"] = BASE_URL

COLLECTION = f"health_graph_{int(time.time())}"

# å®Œæ•´çš„Mem0é…ç½® - åŒæ—¶ä½¿ç”¨Neo4jå’ŒQdrant
full_config = {
    "llm": {
        "provider": "openai",
        "config": {
            "model": "gpt-4o-mini",
            "api_key": API_KEY,
        }
    },
    "embedder": {
        "provider": "openai",
        "config": {
            "model": "text-embedding-3-small",
            "api_key": API_KEY
        }
    },
    "vector_store": {
        "provider": "qdrant",
        "config": {
            "host": "localhost",
            "port": 6333,
            "collection_name": COLLECTION,
        }
    },
    "graph_store": {
        "provider": "neo4j",
        "config": {
            "url": "bolt://localhost:7687",
            "username": "neo4j",
            "password": "Shucheng6"
        }
    }
}

# ç®€åŒ–é…ç½®ï¼ˆä»…å‘é‡å­˜å‚¨ï¼‰
simple_config = {
    "llm": {
        "provider": "openai",
        "config": {
            "model": "gpt-4o-mini",
            "api_key": API_KEY,
        }
    },
    "embedder": {
        "provider": "openai",
        "config": {
            "model": "text-embedding-3-small",
            "api_key": API_KEY
        }
    },
    "vector_store": {
        "provider": "qdrant",
        "config": {
            "host": "localhost",
            "port": 6333,
            "collection_name": COLLECTION,
        }
    }
}

class EnhancedHealthBot:
    """å¢å¼ºç‰ˆå¥åº·åŠ©ç†ï¼Œæ­£ç¡®ä½¿ç”¨Neo4jå›¾å­˜å‚¨"""
    
    def __init__(self, user_id, use_graph_store=True):
        self.user_id = user_id
        self.use_graph_store = use_graph_store
        
        # æ ¹æ®é€‰æ‹©ä½¿ç”¨ä¸åŒçš„é…ç½®
        chosen_config = full_config if use_graph_store else simple_config
        
        try:
            self.memory = Memory.from_config(chosen_config)
            
            # å¦‚æœä½¿ç”¨å›¾å­˜å‚¨ï¼Œå¯ç”¨å›¾åŠŸèƒ½
            if use_graph_store and hasattr(self.memory, 'enable_graph'):
                self.memory.enable_graph = True
                
            self.config_type = "Neo4jå›¾+Qdrantå‘é‡" if use_graph_store else "Qdrantå‘é‡"
            st.success(f"âœ… åˆå§‹åŒ–æˆåŠŸ ({self.config_type})")
            
        except Exception as e:
            st.error(f"åˆå§‹åŒ–å¤±è´¥: {e}")
            # é™çº§åˆ°çº¯å‘é‡å­˜å‚¨
            self.memory = Memory.from_config(simple_config)
            self.use_graph_store = False
            self.config_type = "Qdrantå‘é‡(é™çº§)"
            st.warning("å·²é™çº§åˆ°çº¯å‘é‡å­˜å‚¨æ¨¡å¼")
        
        self.client = OpenAI(api_key=API_KEY, base_url=BASE_URL)
        self.conversation_history = []
    
    def add_health_memory(self, message, category=None):
        """æ·»åŠ å¥åº·è®°å¿†ï¼ŒåŒ…å«åˆ†ç±»ä¿¡æ¯"""
        metadata = {"user_id": self.user_id}
        if category:
            metadata["category"] = category
        
        try:
            # æ·»åŠ åˆ°Mem0ï¼ˆä¼šåŒæ—¶å­˜å‚¨åˆ°å‘é‡å’Œå›¾ï¼‰
            result = self.memory.add(
                message,
                user_id=self.user_id,
                metadata=metadata
            )
            return result
        except Exception as e:
            st.error(f"æ·»åŠ è®°å¿†å¤±è´¥: {e}")
            return None
    
    def get_all_memories(self):
        """è·å–æ‰€æœ‰è®°å¿†ï¼ˆå‘é‡å­˜å‚¨ï¼‰"""
        try:
            # è·å–å‘é‡å­˜å‚¨ä¸­çš„è®°å¿†
            vector_memories = self.memory.get_all(user_id=self.user_id)
            
            memories_list = []
            if isinstance(vector_memories, dict) and 'results' in vector_memories:
                memories_list = vector_memories['results']
            elif isinstance(vector_memories, list):
                memories_list = vector_memories
            
            return memories_list
        except Exception as e:
            print(f"è·å–è®°å¿†å¤±è´¥: {e}")
            return []
    
    def get_graph_data(self):
        """è·å–å›¾æ•°æ®åº“ä¸­çš„å…³ç³»æ•°æ®"""
        if not self.use_graph_store:
            return None
        
        try:
            if hasattr(self.memory, 'graph'):
                graph = self.memory.graph
                
                # æ ¹æ®æµ‹è¯•ç»“æœï¼Œget_alléœ€è¦filterså‚æ•°
                if hasattr(graph, 'get_all'):
                    try:
                        # å°è¯•è·å–ç”¨æˆ·ç›¸å…³çš„å›¾æ•°æ®
                        filters = {"user_id": self.user_id}
                        graph_data = graph.get_all(filters)
                        return graph_data
                    except Exception as e:
                        print(f"è·å–å›¾æ•°æ®å¤±è´¥: {e}")
                        
                        # å°è¯•å…¶ä»–æ–¹æ³•
                        if hasattr(graph, 'search'):
                            try:
                                # ä½¿ç”¨searchæ–¹æ³•è·å–å›¾æ•°æ®
                                graph_data = graph.search(
                                    query="å¥åº·",
                                    user_id=self.user_id,
                                    limit=10
                                )
                                return graph_data
                            except Exception as e2:
                                print(f"å›¾æœç´¢å¤±è´¥: {e2}")
                                
        except Exception as e:
            print(f"è®¿é—®å›¾å­˜å‚¨å¤±è´¥: {e}")
        
        return None
    
    def search_memories(self, query, limit=5):
        """æœç´¢ç›¸å…³è®°å¿†"""
        try:
            # ä½¿ç”¨Mem0çš„æœç´¢åŠŸèƒ½ï¼ˆä¼šåŒæ—¶æœç´¢å‘é‡å’Œå›¾ï¼‰
            search_result = self.memory.search(
                query=query,
                user_id=self.user_id,
                limit=limit
            )
            
            memories = []
            if isinstance(search_result, dict) and 'results' in search_result:
                memories = search_result['results']
            elif isinstance(search_result, list):
                memories = search_result
            
            return memories
        except Exception as e:
            print(f"æœç´¢å¤±è´¥: {e}")
            return []
    
    def categorize_message(self, message):
        """è‡ªåŠ¨åˆ†ç±»å¥åº·ä¿¡æ¯"""
        categories = {
            "ç—‡çŠ¶": ["å¤´ç—›", "å‘çƒ§", "ç–¼ç—›", "ä¸é€‚", "éš¾å—", "ç—›", "æ™•", "ç´¯"],
            "ç”¨è¯": ["è¯", "åƒè¯", "æœç”¨", "åŒ»ç”Ÿå»ºè®®", "å¤„æ–¹"],
            "æ£€æŸ¥": ["è¡€å‹", "è¡€ç³–", "ä½“æ¸©", "æ£€æŸ¥", "åŒ–éªŒ", "æŒ‡æ ‡"],
            "è¿åŠ¨": ["è·‘æ­¥", "é”»ç‚¼", "è¿åŠ¨", "å¥èº«", "æ•£æ­¥"],
            "é¥®é£Ÿ": ["åƒ", "é¥®é£Ÿ", "è¥å…»", "é£Ÿç‰©", "å–"],
            "è¿‡æ•": ["è¿‡æ•", "è¿‡æ•åŸ", "è¿‡æ•å²"],
            "å®¶æ—å²": ["çˆ¶äº²", "æ¯äº²", "å®¶æ—", "é—ä¼ ", "ç—…å²"]
        }
        
        for category, keywords in categories.items():
            for keyword in keywords:
                if keyword in message:
                    return category
        return "å…¶ä»–"
    
    def chat(self, message):
        """å¤„ç†å¯¹è¯"""
        # æ·»åŠ åˆ°å¯¹è¯å†å²
        self.conversation_history.append(f"ç”¨æˆ·: {message}")
        
        # åˆ†ç±»å¹¶å­˜å‚¨
        category = self.categorize_message(message)
        self.add_health_memory(f"ç”¨æˆ·[{category}]: {message}", category)
        
        # æ„å»ºä¸Šä¸‹æ–‡
        context = self._build_context(message)
        
        # è°ƒç”¨GPTç”Ÿæˆå›å¤
        try:
            response = self.client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {
                        "role": "system", 
                        "content": f"""ä½ æ˜¯ä¸“ä¸šçš„å¥åº·åŠ©ç†ã€‚
å­˜å‚¨æ¨¡å¼: {self.config_type}
åŸºäºç”¨æˆ·çš„å¥åº·å†å²å’Œå½“å‰é—®é¢˜ï¼Œæä¾›ä¸“ä¸šã€æ¸©æš–çš„å¥åº·å»ºè®®ã€‚
å›ç­”ç®€æ´æ˜äº†ï¼Œ100å­—ä»¥å†…ã€‚
å¦‚æœå‘ç°æ½œåœ¨å¥åº·é£é™©ï¼Œæ¸©å’Œåœ°æé†’å°±åŒ»ã€‚"""
                    },
                    {
                        "role": "user", 
                        "content": f"{context}\n\nå½“å‰é—®é¢˜: {message}"
                    }
                ],
                max_tokens=150,
                temperature=0.7
            )
            
            reply = response.choices[0].message.content.strip()
            
        except Exception as e:
            reply = f"æŠ±æ­‰ï¼Œå¤„ç†è¯·æ±‚æ—¶å‡ºé”™: {str(e)[:100]}"
        
        # å­˜å‚¨åŠ©ç†å›å¤
        self.conversation_history.append(f"åŠ©ç†: {reply}")
        self.add_health_memory(f"åŠ©ç†å›å¤: {reply}", "å»ºè®®")
        
        return reply
    
    def _build_context(self, message):
        """æ„å»ºå¯¹è¯ä¸Šä¸‹æ–‡"""
        context_parts = []
        
        # 1. æœ€è¿‘çš„å¯¹è¯å†å²
        if self.conversation_history:
            recent = self.conversation_history[-6:]  # æœ€è¿‘3è½®
            context_parts.append("=== æœ€è¿‘å¯¹è¯ ===")
            context_parts.extend(recent)
        
        # 2. æœç´¢ç›¸å…³è®°å¿†
        memories = self.search_memories(message, limit=5)
        if memories:
            context_parts.append("\n=== ç›¸å…³å¥åº·è®°å½• ===")
            for memory in memories:
                text = memory.get('memory', str(memory))
                score = memory.get('score', 0)
                context_parts.append(f"- {text} (ç›¸å…³åº¦: {score:.2f})")
        
        # 3. å¦‚æœä½¿ç”¨å›¾å­˜å‚¨ï¼Œå°è¯•è·å–å…³ç³»ä¿¡æ¯
        if self.use_graph_store:
            graph_data = self.get_graph_data()
            if graph_data:
                context_parts.append("\n=== å¥åº·å…³ç³»å›¾è°± ===")
                context_parts.append(f"å›¾æ•°æ®: {str(graph_data)[:200]}...")
        
        return "\n".join(context_parts)
    
    def get_health_summary(self):
        """ç”Ÿæˆå¥åº·æ‘˜è¦"""
        memories = self.get_all_memories()
        
        if not memories:
            return "æš‚æ— å¥åº·è®°å½•"
        
        # æŒ‰ç±»åˆ«æ•´ç†è®°å¿†
        categories = {}
        for memory in memories:
            text = memory.get('memory', '')
            # å°è¯•ä»æ–‡æœ¬ä¸­æå–ç±»åˆ«
            if '[' in text and ']' in text:
                cat = text[text.find('[')+1:text.find(']')]
                if cat not in categories:
                    categories[cat] = []
                categories[cat].append(text)
            else:
                if 'å…¶ä»–' not in categories:
                    categories['å…¶ä»–'] = []
                categories['å…¶ä»–'].append(text)
        
        # ç”Ÿæˆæ‘˜è¦
        summary_parts = ["ğŸ“‹ å¥åº·æ¡£æ¡ˆæ‘˜è¦\n"]
        for cat, items in categories.items():
            if items:
                summary_parts.append(f"\n**{cat}**")
                for item in items[:3]:  # æ¯ç±»æœ€å¤šæ˜¾ç¤º3æ¡
                    summary_parts.append(f"â€¢ {item}")
        
        return "\n".join(summary_parts)
    
    def clear_all(self):
        """æ¸…é™¤æ‰€æœ‰æ•°æ®"""
        try:
            # æ¸…é™¤å‘é‡å­˜å‚¨
            memories = self.get_all_memories()
            for memory in memories:
                if 'id' in memory:
                    self.memory.delete(memory['id'])
            
            # æ¸…é™¤å¯¹è¯å†å²
            self.conversation_history = []
            
            # å¦‚æœæœ‰å›¾å­˜å‚¨ï¼Œå°è¯•æ¸…é™¤
            if self.use_graph_store and hasattr(self.memory, 'graph'):
                try:
                    if hasattr(self.memory.graph, 'reset'):
                        self.memory.graph.reset()
                except Exception as e:
                    print(f"æ¸…é™¤å›¾æ•°æ®å¤±è´¥: {e}")
            
            return True
        except Exception as e:
            print(f"æ¸…é™¤å¤±è´¥: {e}")
            return False

# ==================== Streamlitç•Œé¢ ====================

st.set_page_config(
    page_title="AIå¥åº·åŠ©ç† - Neo4jå¢å¼ºç‰ˆ",
    page_icon="ğŸ¥",
    layout="wide"
)

# æ ‡é¢˜æ 
col1, col2, col3 = st.columns([2, 1, 1])
with col1:
    st.title("ğŸ¥ AIå¥åº·åŠ©ç† (Neo4jå¢å¼ºç‰ˆ)")
with col2:
    st.caption("GPT-4o-mini")
with col3:
    st.caption(f"é›†åˆ: {COLLECTION[:15]}...")

# ä¾§è¾¹æ 
with st.sidebar:
    st.header("âš™ï¸ è®¾ç½®")
    
    user_id = st.text_input("ç”¨æˆ·ID", value="health_user_001")
    
    # å­˜å‚¨æ¨¡å¼é€‰æ‹©
    st.subheader("ğŸ—„ï¸ å­˜å‚¨æ¨¡å¼")
    storage_mode = st.radio(
        "é€‰æ‹©å­˜å‚¨æ–¹å¼",
        ["Neo4jå›¾+Qdrantå‘é‡", "ä»…Qdrantå‘é‡"],
        index=0
    )
    use_graph = (storage_mode == "Neo4jå›¾+Qdrantå‘é‡")
    
    # æ˜¾ç¤ºå­˜å‚¨ä¿¡æ¯
    if use_graph:
        st.info("""
        ğŸŒ **å›¾æ•°æ®åº“æ¨¡å¼**
        - Neo4jå­˜å‚¨å®ä½“å…³ç³»
        - Qdrantå­˜å‚¨å‘é‡åµŒå…¥
        - æ”¯æŒå¤æ‚å…³ç³»æŸ¥è¯¢
        """)
    else:
        st.success("""
        ğŸ“ **å‘é‡æ•°æ®åº“æ¨¡å¼**
        - ä»…ä½¿ç”¨Qdrant
        - åŸºäºè¯­ä¹‰ç›¸ä¼¼åº¦æœç´¢
        """)
    
    st.divider()
    
    # è®°å¿†ç»Ÿè®¡
    if "bot" in st.session_state:
        bot = st.session_state.bot
        memories = bot.get_all_memories()
        
        st.subheader("ğŸ§  è®°å¿†ç»Ÿè®¡")
        col1, col2 = st.columns(2)
        with col1:
            st.metric("æ€»è®°å¿†", len(memories))
        with col2:
            st.metric("å¯¹è¯è½®æ•°", len(bot.conversation_history)//2)
        
        # å¥åº·æ‘˜è¦
        with st.expander("ğŸ“Š å¥åº·æ¡£æ¡ˆ", expanded=False):
            summary = bot.get_health_summary()
            st.markdown(summary)
        
        # å›¾æ•°æ®ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if use_graph:
            with st.expander("ğŸŒ å›¾æ•°æ®", expanded=False):
                graph_data = bot.get_graph_data()
                if graph_data:
                    st.json(graph_data)
                else:
                    st.info("æš‚æ— å›¾æ•°æ®")
    
    st.divider()
    
    # å¿«é€Ÿæ“ä½œ
    st.subheader("âš¡ å¿«é€Ÿæ“ä½œ")
    
    # é¢„è®¾é—®é¢˜
    quick_questions = {
        "ç—‡çŠ¶è®°å½•": [
            "æˆ‘æœ€è¿‘ç»å¸¸å¤´ç—›",
            "æ˜¨å¤©å¼€å§‹å‘çƒ§38åº¦",
            "èƒƒéƒ¨ä¸é€‚å·²ç»3å¤©äº†"
        ],
        "å¥åº·å’¨è¯¢": [
            "è¡€å‹140/90éœ€è¦æ³¨æ„ä»€ä¹ˆ",
            "å¦‚ä½•æ”¹å–„ç¡çœ è´¨é‡",
            "æ„Ÿå†’äº†è¯¥æ€ä¹ˆåŠ"
        ],
        "ç”Ÿæ´»ä¹ æƒ¯": [
            "æˆ‘æ¯å¤©è·‘æ­¥5å…¬é‡Œ",
            "æœ€è¿‘å¼€å§‹ä½ç›é¥®é£Ÿ",
            "æˆ’çƒŸå·²ç»ä¸€ä¸ªæœˆäº†"
        ]
    }
    
    for category, questions in quick_questions.items():
        st.caption(f"**{category}**")
        cols = st.columns(1)
        for q in questions:
            if st.button(q, key=f"q_{q}", use_container_width=True):
                st.session_state.pending_question = q
    
    st.divider()
    
    # ç®¡ç†æŒ‰é’®
    col1, col2 = st.columns(2)
    with col1:
        if st.button("ğŸ”„ æ–°å¯¹è¯", use_container_width=True):
            if "bot" in st.session_state:
                st.session_state.bot.conversation_history = []
            st.session_state.messages = []
            st.rerun()
    
    with col2:
        if st.button("ğŸ—‘ï¸ æ¸…é™¤æ‰€æœ‰", use_container_width=True):
            if "bot" in st.session_state:
                if st.session_state.bot.clear_all():
                    st.success("å·²æ¸…é™¤æ‰€æœ‰æ•°æ®")
                else:
                    st.warning("æ¸…é™¤å¤±è´¥")
                st.session_state.messages = []
                st.rerun()

# ä¸»ç•Œé¢
# åˆå§‹åŒ–ä¼šè¯çŠ¶æ€
if "messages" not in st.session_state:
    st.session_state.messages = []

# åˆå§‹åŒ–æˆ–é‡æ–°åˆå§‹åŒ–æœºå™¨äºº
need_reinit = False
if "bot" in st.session_state:
    if st.session_state.bot.use_graph_store != use_graph:
        need_reinit = True

if "bot" not in st.session_state or need_reinit:
    with st.spinner("åˆå§‹åŒ–å¥åº·åŠ©ç†..."):
        try:
            st.session_state.bot = EnhancedHealthBot(user_id, use_graph)
        except Exception as e:
            st.error(f"åˆå§‹åŒ–å¤±è´¥: {e}")
            st.stop()

# æ˜¾ç¤ºæ¬¢è¿æ¶ˆæ¯
if not st.session_state.messages:
    welcome_msg = f"""
ğŸ‘‹ ä½ å¥½ï¼æˆ‘æ˜¯ä½ çš„AIå¥åº·åŠ©ç†ã€‚

æˆ‘ä½¿ç”¨ **{st.session_state.bot.config_type}** å­˜å‚¨ç³»ç»Ÿæ¥ï¼š
â€¢ ğŸ“ è®°å½•ä½ çš„å¥åº·ä¿¡æ¯å’Œç—‡çŠ¶
â€¢ ğŸ” æ™ºèƒ½åˆ†æå¥åº·è¶‹åŠ¿
â€¢ ğŸ’Š æä¾›ä¸ªæ€§åŒ–å¥åº·å»ºè®®
â€¢ ğŸ¥ æé†’åŠæ—¶å°±åŒ»

è¯·å‘Šè¯‰æˆ‘ä½ çš„å¥åº·çŠ¶å†µï¼Œæˆ–ç‚¹å‡»å·¦ä¾§çš„å¿«é€Ÿé—®é¢˜å¼€å§‹ã€‚
"""
    st.session_state.messages.append({
        "role": "assistant",
        "content": welcome_msg
    })

# æ˜¾ç¤ºå¯¹è¯å†å²
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# å¤„ç†å¾…å¤„ç†çš„é—®é¢˜
if "pending_question" in st.session_state:
    question = st.session_state.pending_question
    del st.session_state.pending_question
    
    # æ˜¾ç¤ºç”¨æˆ·æ¶ˆæ¯
    with st.chat_message("user"):
        st.markdown(question)
    st.session_state.messages.append({"role": "user", "content": question})
    
    # ç”Ÿæˆå¹¶æ˜¾ç¤ºå›å¤
    with st.chat_message("assistant"):
        with st.spinner("åˆ†æä¸­..."):
            response = st.session_state.bot.chat(question)
            st.markdown(response)
    st.session_state.messages.append({"role": "assistant", "content": response})
    
    st.rerun()

# èŠå¤©è¾“å…¥æ¡†
if prompt := st.chat_input("è¯·æè¿°ä½ çš„å¥åº·çŠ¶å†µæˆ–æå‡ºé—®é¢˜..."):
    # æ˜¾ç¤ºç”¨æˆ·æ¶ˆæ¯
    with st.chat_message("user"):
        st.markdown(prompt)
    st.session_state.messages.append({"role": "user", "content": prompt})
    
    # ç”Ÿæˆå¹¶æ˜¾ç¤ºå›å¤
    with st.chat_message("assistant"):
        with st.spinner("æ€è€ƒä¸­..."):
            response = st.session_state.bot.chat(prompt)
            st.markdown(response)
    st.session_state.messages.append({"role": "assistant", "content": response})
    
    st.rerun()

# åº•éƒ¨ä¿¡æ¯æ 
st.markdown("---")
col1, col2, col3 = st.columns([2, 1, 1])
with col1:
    st.caption("âš ï¸ å¥åº·å»ºè®®ä»…ä¾›å‚è€ƒï¼Œä¸¥é‡ç—‡çŠ¶è¯·åŠæ—¶å°±åŒ»")
with col2:
    if "bot" in st.session_state:
        st.caption(f"ğŸ’¾ {st.session_state.bot.config_type}")
with col3:
    st.caption(f"ç”¨æˆ·: {user_id}")

# è¿è¡Œå‘½ä»¤ï¼š
# streamlit run enhanced_health_mem0_neo4j.py