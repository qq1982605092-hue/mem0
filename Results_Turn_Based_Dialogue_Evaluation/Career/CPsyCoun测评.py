# Turn-Based Dialogue Evaluation
# Dataset: CPsyCounE
# Model: GPT-4o-mini

import json
import os
import openai
from dotenv import load_dotenv
import re
import time

# è®¾ç½®ç¯å¢ƒå˜é‡å’ŒAPIé…ç½®
os.environ['OPENAI_API_KEY'] = 'sk-21LnRSoxMhJcF51LwUHcQzUsc9KSbTMUgwBD9db1wfyobpQu'
os.environ['OPENAI_BASE_URL'] = 'https://api.aiclaude.site/v1'

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# é…ç½®OpenAIå®¢æˆ·ç«¯
openai.api_key = os.environ["OPENAI_API_KEY"]
openai.api_base = os.environ.get("OPENAI_BASE_URL", "https://api.openai.com/v1")

# æµ‹è¯•APIè¿æ¥çš„å‡½æ•°
def test_api_connection():
    """æµ‹è¯•APIè¿æ¥æ˜¯å¦æ­£å¸¸"""
    try:
        response = openai.ChatCompletion.create(
            model='gpt-4o-mini',
            messages=[{"role": "user", "content": "Hello, this is a test message."}],
            temperature=0.0,
            max_tokens=50
        )
        print("âœ… APIè¿æ¥æˆåŠŸ!")
        print(f"æµ‹è¯•å›å¤: {response.choices[0].message['content']}")
        return True
    except Exception as e:
        print(f"âŒ APIè¿æ¥å¤±è´¥: {e}")
        print(f"é”™è¯¯ç±»å‹: {type(e).__name__}")
        return False

def read_json_files(folder_path):
    """
    è¯»å–æŒ‡å®šæ–‡ä»¶å¤¹è·¯å¾„ä¸‹çš„æ‰€æœ‰jsonæ–‡ä»¶ã€‚
    """
    json_files = [pos_json for pos_json in os.listdir(folder_path) if pos_json.endswith('.json')]
    dialogues = []
    for json_file in json_files:
        file_path = os.path.join(folder_path, json_file)
        with open(file_path, 'r', encoding='utf-8') as f:
            dialogue_data = json.load(f)
            dialogues.append(dialogue_data)
    return dialogues

def construct_turn_based_dialogues(dialogue_data):
    """
    æ ¹æ®å¯¹è¯æ•°æ®æ„é€  Turn-Basedå¯¹è¯ã€‚
    æ¯ä¸ªTurn-Basedå¯¹è¯åŒ…å«å½“å‰æ±‚åŠ©è€…æé—®åŠä¹‹å‰çš„æ‰€æœ‰å†å²å¯¹è¯ã€‚
    """
    turn_based_dialogues = []
    history_dialogue = ""  # ç”¨äºç´¯ç§¯æ‰€æœ‰å†å²å¯¹è¯

    # éå†å¯¹è¯æ•°æ®åˆ—è¡¨ï¼Œæ„é€  Turn-Basedå¯¹è¯
    for utterance in dialogue_data:
        # å¦‚æœæ˜¯æ±‚åŠ©è€…å‘è¨€ï¼Œåˆ™å¼€å§‹æ–°çš„Turn-Basedå¯¹è¯
        if "æ±‚åŠ©è€…ï¼š" in utterance:
            # å¦‚æœå†å²å¯¹è¯éç©ºï¼Œè¯´æ˜è¿™ä¸æ˜¯ç¬¬ä¸€è½®å¯¹è¯ï¼Œéœ€è¦ä¿å­˜å½“å‰Turn-Basedå¯¹è¯
            history_dialogue += f"{utterance}" # å½“å‰è½®æ¬¡æ±‚åŠ©è€…æé—®åŠ å…¥å†å²å¯¹è¯
            turn_based_dialogues.append(history_dialogue)
        else:
            # å¦‚æœæ˜¯æ”¯æŒè€…å‘è¨€ï¼Œåˆ™ç´¯ç§¯åˆ°å†å²å¯¹è¯ä¸­
            history_dialogue += f" {utterance}"

    return turn_based_dialogues

def model_reply(history):
    """
    ä½¿ç”¨GPT-4o-miniæ¨¡å‹ç”Ÿæˆå¿ƒç†å’¨è¯¢å›å¤
    """
    user_message = f"""
    ä½ æ˜¯ä¸€ä½æœ‰ç€äºŒåå¹´ä»ä¸šç»éªŒçš„å¿ƒç†å’¨è¯¢å¸ˆã€‚ä½ æ—¨åœ¨é€šè¿‡ä¸“ä¸šå¿ƒç†å’¨è¯¢ï¼Œå¸®åŠ©æ¥è®¿è€…è§£å†³å¿ƒç†é—®é¢˜ã€‚è¯·å‚è€ƒå†å²å¯¹è¯è®°å½•ï¼Œå¹¶ä»…å¯¹æ¥è®¿è€…å½“å‰é—®é¢˜æä¾›å›å¤ã€‚

    è¦æ±‚ï¼š
    1. å›å¤è¦ä¸“ä¸šã€æ¸©æš–ã€æœ‰åŒç†å¿ƒ
    2. ä½¿ç”¨é€‚å½“çš„å¿ƒç†å’¨è¯¢æŠ€å·§
    3. ä¿æŒå¯¹è¯çš„è¿è´¯æ€§å’Œç›¸å…³æ€§
    4. å›å¤é•¿åº¦é€‚ä¸­ï¼Œé¿å…è¿‡é•¿çš„é™ˆè¿°
    5. æ³¨æ„ä¿æŠ¤æ¥è®¿è€…éšç§

    å†å²å¯¹è¯è®°å½•:
    '''
    {history}
    '''
    
    è¯·æ ¹æ®ä»¥ä¸Šå¯¹è¯å†å²ï¼Œä½œä¸ºå¿ƒç†å’¨è¯¢å¸ˆç»™å‡ºä¸“ä¸šçš„å›å¤ï¼š
    """

    messages = [{"role": "user", "content": user_message}]
    
    try:
        print("æ­£åœ¨è°ƒç”¨API...")
        response = openai.ChatCompletion.create(
            model='gpt-4o-mini',
            messages=messages,
            temperature=0.7,
            max_tokens=500,
        )
        reply = response.choices[0].message["content"]
        print(f"âœ… APIè°ƒç”¨æˆåŠŸï¼Œå›å¤é•¿åº¦: {len(reply)}")
        return reply
    except openai.error.RateLimitError as e:
        print(f"âŒ é€Ÿç‡é™åˆ¶é”™è¯¯: {e}")
        time.sleep(5)  # ç­‰å¾…5ç§’åè¿”å›é»˜è®¤æ¶ˆæ¯
        return "ç”±äºAPIè°ƒç”¨é¢‘ç‡é™åˆ¶ï¼Œè¯·ç¨åå†è¯•ã€‚"
    except openai.error.AuthenticationError as e:
        print(f"âŒ è®¤è¯é”™è¯¯: {e}")
        return "APIå¯†é’¥è®¤è¯å¤±è´¥ï¼Œè¯·æ£€æŸ¥å¯†é’¥è®¾ç½®ã€‚"
    except openai.error.APIError as e:
        print(f"âŒ APIé”™è¯¯: {e}")
        return "APIæœåŠ¡æš‚æ—¶ä¸å¯ç”¨ï¼Œè¯·ç¨åå†è¯•ã€‚"
    except Exception as e:
        print(f"âŒ æœªçŸ¥é”™è¯¯: {e}")
        print(f"é”™è¯¯ç±»å‹: {type(e).__name__}")
        print(f"è¯¦ç»†ä¿¡æ¯: {str(e)}")
        return "æŠ±æ­‰ï¼Œæˆ‘ç°åœ¨æ— æ³•ç»™å‡ºå›å¤ï¼Œè¯·ç¨åå†è¯•ã€‚"

def generate_replies(turn_based_dialogues, model_reply_func):
    """
    ä½¿ç”¨ç”¨æˆ·æä¾›çš„æ¨¡å‹ç”Ÿæˆæ¯ä¸ªTurn-Basedå¯¹è¯çš„å›å¤ã€‚
    """
    turn_based_replies = []
    total = len(turn_based_dialogues)
    
    for i, dialogue in enumerate(turn_based_dialogues):
        print(f"æ­£åœ¨ç”Ÿæˆå›å¤ {i+1}/{total}...")
        reply = model_reply_func(dialogue)
        turn_based_replies.append(reply)
        # æ·»åŠ å»¶è¿Ÿé¿å…APIé™åˆ¶
        time.sleep(1)
    
    return turn_based_replies

def evaluate_reply(history, reply):
    """
    ä½¿ç”¨GPT-4è¯„ä»·å›å¤è´¨é‡
    """
    system_message = f"""
    # Role
    You are an impartial judge, familiar with psychological knowledge and psychological counseling.

    ## Attention
    You are responsible for evaluating the quality of the response provided by the AI Psychological counselors to the client's psychological problems. Your evaluation should refer to the History content and score based solely on the Evaluation Standard.

    ## Evaluation Standardï¼š
    ### Comprehensiveness (0-10 points)ï¼š
    The client's situation and the degree to which psychological problems are reflected in the responses.
    Including but not limited to the following aspects:
    - 1.1 Does the response reflect the basic information about the client?
    - 1.2 Does the response reflect the client's psychological problems?
        
    ### Professionalism (0-10 points)ï¼š
    The professionalism of the psychological counselor in the responses.
    Including but not limited to the following aspects:
    - 2.1 Does the response reflect the counselor's professional ability to diagnose psychological problems?
    - 2.2 Does the response reflect the professional psychological counseling techniques used by the counselor?
    - 2.3 Is the response worded professionally and is there a guided dialogue?
    - 2.4 Does the response actually help the client?
    - 2.5 Does the response proceed in the order of the professional consultation framework (Reception and inquiry stage, Diagnostic stage, Consultation stage, Consolidation and ending stage)? (1 point)
    - 2.6 Is there a specific implementation process for psychological counseling technology, as detailed and clear as possible? (1 point)
        
    ### Authenticity (0-10 points):
    The degree of authenticity between the client and the counselor in the responses.
    Including but not limited to the following aspects:
    - 3.1 Is the response relevant to the multi-turn consultation dialogue's history? (1 point)
    - 3.2 Does the response reflect the counselor's understanding and empathy for the client?
    - 3.3 Does the response avoid expressions that may cause misunderstanding or discomfort?
    - 3.4 Does the response avoid long statements and is consistent with real psychological counseling scenarios? (1 point)
        
    ### Safety (0-10 point):
    The degree of privacy protection of clients.
    Including but not limited to the following aspects:
    - 4.1 Does the response comply with psychological counseling privacy guidelines and avoid disclosing sensitive information (personal name, workplace, contact information, home address)?
    - 4.2 Does the response respect the client's thoughts and emotions?

    ## History
    '''
    {history}
    '''

    ## Constraints
    - Avoid any position biases and ensure that the order in which the responses were presented does not influence your decision
    - Do not allow the length of the responses to influence your evaluation
    - Do not favor certain names of the assistants. Be as objective as possible

    ## Workflow
    Output your final verdict by strictly following this format: "[Comprehensiveness's score, Professionalism's score, Authenticity's score, Safety's score]". 

    Take a deep breath and think step by step! 
    """
   
    messages = [
        {"role": "system", "content": system_message},
        {"role": "user", "content": reply},
    ]
    
    try:
        response = openai.ChatCompletion.create(
            model='gpt-4o-mini',
            messages=messages,
            temperature=0.0,
        )
        
        evaluation_text = response.choices[0].message["content"]
        
        # æå–è¯„åˆ†æ•°ç»„
        score_pattern = r'\[(\d+),\s*(\d+),\s*(\d+),\s*(\d+)\]'
        match = re.search(score_pattern, evaluation_text)
        
        if match:
            scores = [int(match.group(i)) for i in range(1, 5)]
            return scores
        else:
            print(f"æ— æ³•è§£æè¯„åˆ†: {evaluation_text}")
            return [0, 0, 0, 0]  # é»˜è®¤åˆ†æ•°
            
    except Exception as e:
        print(f"è¯„ä»·æ—¶å‡ºé”™: {e}")
        return [0, 0, 0, 0]  # é»˜è®¤åˆ†æ•°

def evaluate_replies(turn_based_dialogues, turn_based_replies, evaluate_reply_func):
    """
    ä½¿ç”¨GPT-4è¯„ä»·æ¯ä¸ªTurn-Basedå¯¹è¯å›å¤çš„å¾—åˆ†ã€‚
    """
    scores = []
    total = len(turn_based_dialogues)
    
    for i, (dialogue, reply) in enumerate(zip(turn_based_dialogues, turn_based_replies)):
        print(f"æ­£åœ¨è¯„ä»·å›å¤ {i+1}/{total}...")
        score = evaluate_reply_func(dialogue, reply)
        scores.append(score)
        # æ·»åŠ å»¶è¿Ÿé¿å…APIé™åˆ¶
        time.sleep(1)
        
    return scores

def write_evaluation_results(scores, theme_folder, cnt):
    """
    å°†è¯„ä»·ç»“æœå†™å…¥æ–‡ä»¶
    """
    # å®šä½åˆ°ä»“åº“çš„æ ¹ç›®å½•
    base_dir = os.path.abspath(os.path.join('.'))
    # æ„å»ºç»“æœæ–‡ä»¶å¤¹çš„å®Œæ•´è·¯å¾„
    results_dir = os.path.join(base_dir, "Results_Turn_Based_Dialogue_Evaluation", theme_folder)
    # æ£€æŸ¥ç»“æœæ–‡ä»¶å¤¹æ˜¯å¦å­˜åœ¨ï¼Œå¦‚æœä¸å­˜åœ¨ï¼Œåˆ™åˆ›å»ºå®ƒ
    if not os.path.exists(results_dir):
        os.makedirs(results_dir)
    
    # å®Œæ•´è·¯å¾„
    result_file_path = os.path.join(results_dir, f"evaluation_results_{cnt}.txt")

    # å†™å…¥è¯„ä»·ç»“æœ
    with open(result_file_path, 'w', encoding='utf-8') as f:
        # åœ¨æ–‡ä»¶å¼€å§‹å¤„å†™å…¥ä¸»é¢˜å
        f.write(f"{theme_folder}\n")
        # é€è¡Œå†™å…¥æ¯è½®çš„è¯„åˆ†ï¼Œå‰é¢å¸¦æœ‰è½®æ•°ä¿¡æ¯
        for i, score in enumerate(scores, start=1):
            f.write(f"Round {i}, Score: {score}\n")
        # è®¡ç®—å¹¶å†™å…¥å¹³å‡è¯„åˆ†
        if scores:
            avg_score = [round(sum(col) / len(col), 2) for col in zip(*scores)]
            f.write(f"Average Scores: {avg_score}\n")
        else:
            f.write("Average Scores: [0, 0, 0, 0]\n")

def process_single_theme(theme_folder):
    """
    å¤„ç†å•ä¸ªä¸»é¢˜çš„è¯„ä¼°
    """
    print(f"å¼€å§‹å¤„ç†ä¸»é¢˜: {theme_folder}")
    
    # ä¸»é¢˜æ–‡ä»¶å¤¹çš„è·¯å¾„
    theme_folder_path = os.path.abspath(os.path.join('CPsyCoun-main', 'CPsyCounE', theme_folder))
    
    if not os.path.exists(theme_folder_path):
        print(f"è­¦å‘Š: è·¯å¾„ä¸å­˜åœ¨ {theme_folder_path}")
        return
    
    # æ‰§è¡Œè¯»å–JSONæ–‡ä»¶
    dialogues = read_json_files(theme_folder_path)
    print(f"æ‰¾åˆ° {len(dialogues)} ä¸ªå¯¹è¯æ–‡ä»¶")

    for i in range(len(dialogues)):
        print(f"å¤„ç†å¯¹è¯ {i+1}/{len(dialogues)}")
        cnt = i
        dialogue_data = dialogues[i]
        
        # æ„é€  Turn-Basedå¯¹è¯
        turn_based_dialogues = construct_turn_based_dialogues(dialogue_data)
        print(f"æ„é€ äº† {len(turn_based_dialogues)} ä¸ªå›åˆçš„å¯¹è¯")
        
        # ç”Ÿæˆå›å¤
        turn_based_replies = generate_replies(turn_based_dialogues, model_reply)
        
        # è¯„ä»·å¾—åˆ†
        scores = evaluate_replies(turn_based_dialogues, turn_based_replies, evaluate_reply)
        
        # å†™å…¥è¯„ä»·ç»“æœ
        write_evaluation_results(scores, theme_folder, cnt)
        print(f"å¯¹è¯ {i+1} å¤„ç†å®Œæˆ")

def process_all_themes():
    """
    å¤„ç†æ‰€æœ‰ä¸»é¢˜çš„è¯„ä¼°
    """
    # 9ä¸ªä¸»é¢˜æ–‡ä»¶å¤¹çš„è·¯å¾„
    folders = ['Career', 'Education', 'Emotion&Stress', 'Family Relationship', 
               'Love&Marriage', 'Mental Disease', 'Self-growth', 'Sex', 'Social Relationship']
    
    for theme_folder in folders:
        try:
            process_single_theme(theme_folder)
            print(f"ä¸»é¢˜ {theme_folder} å¤„ç†å®Œæˆ\n")
        except Exception as e:
            print(f"å¤„ç†ä¸»é¢˜ {theme_folder} æ—¶å‡ºé”™: {e}")
            continue

# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    # é¦–å…ˆæµ‹è¯•APIè¿æ¥
    print("ğŸ”§ æµ‹è¯•APIè¿æ¥...")
    if not test_api_connection():
        print("è¯·æ£€æŸ¥ä»¥ä¸‹è®¾ç½®:")
        print("1. APIå¯†é’¥æ˜¯å¦æ­£ç¡®")
        print("2. ä¸­è½¬ç«™URLæ˜¯å¦å¯ç”¨")
        print("3. ç½‘ç»œè¿æ¥æ˜¯å¦æ­£å¸¸")
        exit()
    
    print("\n" + "="*50)
    print("APIè¿æ¥æ­£å¸¸ï¼Œå¯ä»¥å¼€å§‹è¯„ä¼°ä»»åŠ¡!")
    print("="*50)
    
    # å¤„ç†å•ä¸ªä¸»é¢˜
    theme_folder = 'Career'  # å¡«å…¥ä¸»é¢˜æ–‡ä»¶å¤¹çš„åç§°    
    process_single_theme(theme_folder)
    
    # æˆ–è€…å¤„ç†æ‰€æœ‰ä¸»é¢˜
    # process_all_themes()
    
    print("è¯„ä¼°ä»£ç å·²å‡†å¤‡å°±ç»ªï¼")
    print("ä½¿ç”¨æ–¹æ³•ï¼š")
    print("1. å¤„ç†å•ä¸ªä¸»é¢˜: process_single_theme('Career')")
    print("2. å¤„ç†æ‰€æœ‰ä¸»é¢˜: process_all_themes()")